# TTS-py üéôÔ∏è

**S√≠ntesis de Voz con Clonaci√≥n Basada en Referencia de Audio**

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![uv](https://img.shields.io/badge/package%20manager-uv-blueviolet)](https://github.com/astral-sh/uv)

TTS-py es una utilidad de l√≠nea de comandos ligera y potente para **convertir texto a audio con clonaci√≥n de voz**. Utiliza Chatterbox TTS de ResembleAI para generar audio natural con la capacidad de imitar voces a partir de muestras de referencia.

---

## ‚ú® Caracter√≠sticas

- üéØ **CLI Simple y Directa** - Interfaz de l√≠nea de comandos intuitiva
- üéôÔ∏è **Clonaci√≥n de Voz** - Genera audio imitando cualquier voz de referencia
- üöÄ **Aceleraci√≥n GPU** - Detecci√≥n autom√°tica de NVIDIA CUDA
- üìù **M√∫ltiples Entradas** - Texto directo o archivos de guion
- üéµ **Formatos Soportados** - WAV, MP3, FLAC para audio de referencia
- üíæ **Cache de Voces** - Sistema inteligente para reutilizar voces procesadas
- üìä **Barra de Progreso** - Indicador visual en tiempo real
- üíª **Workflow Moderno** - Gesti√≥n de paquetes con `uv`
- üîß **Robusto** - Manejo de errores y validaciones completas

---

## üéØ Casos de Uso

- üìñ **Audiolibros personalizados** - Convierte tus notas o textos a audio
- üé¨ **Producci√≥n de videos** - Narraciones con voces personalizadas
- üé≠ **Historias multi-personaje** - Genera voces distintas para cada personaje
- üéôÔ∏è **Podcasts** - Producci√≥n de contenido de audio
- üìù **Documentos a audio** - Escucha tus apuntes mientras haces otras cosas
- üéÆ **Voces para juegos** - Crea voces para personajes de proyectos creativos

---

## üöÄ Instalaci√≥n

### Requisitos

- **Python 3.11+**
- **uv** (gestor de paquetes moderno)
- **GPU NVIDIA con CUDA** (recomendado, funciona en CPU tambi√©n)
- **~8GB de espacio en disco** (para modelos)

### Paso 1: Instalar uv

```bash
# Linux/macOS
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### Paso 2: Clonar el Repositorio

```bash
git clone https://github.com/pyllm-utilities/tts-py.git
cd tts-py
```

### Paso 3: Instalar Dependencias

```bash
# uv crear√° autom√°ticamente el entorno virtual e instalar√° todo
uv sync
```

**Nota para WSL2:** Si est√°s en WSL2 y tienes problemas de red, ejecuta:
```bash
# Deshabilitar IPv6 (solo si tienes errores de conexi√≥n)
sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1
sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1
```

---

## üìñ Uso

### Sintaxis B√°sica

```bash
uv run main.py [OPCIONES]
```

### Ejemplos

#### 1. Texto Simple

Genera audio a partir de texto directamente:

```bash
uv run main.py --text "Hola, bienvenido a TTS-py" --output salida.wav
```

#### 2. Desde Archivo de Guion

Lee el texto desde un archivo:

```bash
uv run main.py --script creative-scripts/mi_guion.txt --output salida.wav
```

#### 3. Con Voz de Referencia (Clonaci√≥n)

Usa una muestra de audio para clonar la voz:

```bash
uv run main.py \
  --text "Este audio usar√° la voz de referencia" \
  --voice audio-samples/mi_voz.wav \
  --output salida.wav
```

#### 4. Guion + Voz de Referencia

Combina un guion extenso con voz personalizada:

```bash
uv run main.py \
  --script creative-scripts/audiolibro.txt \
  --voice audio-samples/narrador.wav \
  --output audiolibro.wav
```

#### 5. Con Cache de Voz (Recomendado)

Guarda la voz procesada para reutilizaci√≥n:

```bash
# Primera vez: procesa y guarda en cache
uv run main.py \
  --text "Primer uso de esta voz" \
  --voice audio-samples/narrador.wav \
  --voice-name "narrador" \
  --output salida1.wav

# Siguientes usos: m√°s r√°pido (usa cache)
uv run main.py \
  --text "Reutilizando la misma voz" \
  --voice audio-samples/narrador.wav \
  --voice-name "narrador" \
  --output salida2.wav
```

#### 6. Forzar Uso de CPU

Si no tienes GPU o quieres usar CPU:

```bash
uv run main.py --text "Texto aqu√≠" --output salida.wav --cpu
```

---

## üéõÔ∏è Opciones de L√≠nea de Comandos

| Opci√≥n | Descripci√≥n |
|--------|-------------|
| `-t, --text TEXT` | Texto a sintetizar directamente desde CLI |
| `-s, --script PATH` | Ruta a archivo .txt con el guion |
| `-v, --voice PATH` | Ruta a audio de referencia para clonar voz (WAV/MP3/FLAC) |
| `--voice-name NAME` | Nombre para guardar/cargar voz desde cache (mejora rendimiento) |
| `-o, --output PATH` | Ruta donde guardar el audio generado (default: `output-dir/output.wav`) |
| `--cpu` | Forzar uso de CPU en lugar de GPU |
| `-h, --help` | Mostrar ayuda completa |

**Notas:**
- `--text` y `--script` son mutuamente excluyentes (usa uno u otro)
- `--voice-name` solo funciona con `--voice`
- El cache se guarda en `~/.cache/tts-py/voices/`

---

## üìÅ Estructura del Proyecto

```
tts-py/
‚îú‚îÄ‚îÄ main.py                 # Script principal
‚îú‚îÄ‚îÄ test_simple.py          # Script de prueba
‚îú‚îÄ‚îÄ pyproject.toml          # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ README.md               # Este archivo
‚îú‚îÄ‚îÄ CHANGELOG.md            # Registro de cambios
‚îú‚îÄ‚îÄ TODO.md                 # Roadmap y tareas pendientes
‚îú‚îÄ‚îÄ CLAUDE.md               # Contexto para desarrollo
‚îú‚îÄ‚îÄ creative-scripts/       # üìù Coloca aqu√≠ tus guiones
‚îÇ   ‚îú‚îÄ‚îÄ ejemplo.txt         # Ejemplo incluido
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Gu√≠a de uso
‚îú‚îÄ‚îÄ audio-samples/          # üéôÔ∏è Coloca aqu√≠ tus muestras de voz
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # Gu√≠a de grabaci√≥n
‚îú‚îÄ‚îÄ output-dir/             # üéµ Audio generado se guarda aqu√≠
‚îî‚îÄ‚îÄ .venv/                  # Entorno virtual (auto-generado)
```

---

## üéôÔ∏è Gu√≠a de Muestras de Audio

Para obtener mejores resultados con clonaci√≥n de voz:

### ‚úÖ Caracter√≠sticas de Buena Muestra

- **Duraci√≥n:** 10-30 segundos m√≠nimo
- **Calidad:** Audio limpio, sin ruido de fondo
- **Contenido:** Habla natural, entonaci√≥n normal
- **Formato:** WAV sin comprimir (44.1kHz o 48kHz recomendado)
- **Voz √∫nica:** Solo una persona hablando

### ‚ùå Evitar

- ‚ùå Audio con m√∫sica de fondo
- ‚ùå Ruido ambiental excesivo
- ‚ùå Susurros o gritos
- ‚ùå M√∫ltiples voces sobrepuestas
- ‚ùå Compresi√≥n excesiva (MP3 de baja calidad)

### üìù Texto Recomendado para Grabar

> "Hola, mi nombre es [tu nombre]. Me gusta leer libros, escuchar m√∫sica y aprender cosas nuevas. Hoy hace un d√≠a soleado y espero que tengas un excelente d√≠a. Gracias por escuchar."

M√°s detalles en: [`audio-samples/README.md`](audio-samples/README.md)

---

## ‚öôÔ∏è Requisitos T√©cnicos

### Hardware Recomendado

- **GPU:** NVIDIA con CUDA (RTX 2060 o superior)
- **VRAM:** 6GB m√≠nimo, 8GB+ recomendado
- **RAM:** 16GB recomendado
- **Disco:** 10GB libres (modelos + cache)

### Hardware M√≠nimo

- **CPU:** Procesador moderno multi-core
- **RAM:** 8GB m√≠nimo
- **Disco:** 10GB libres

**Nota:** Sin GPU, la generaci√≥n ser√° significativamente m√°s lenta (10-20x m√°s tiempo).

---

## üîß Soluci√≥n de Problemas

### Error: "No module named 'chatterbox'"

```bash
# Reinstalar dependencias
uv sync
```

### Error: "CUDA not available" (teniendo GPU NVIDIA)

1. Verifica drivers NVIDIA: `nvidia-smi`
2. Reinstala PyTorch con CUDA:
   ```bash
   uv add torch torchaudio --index-url https://download.pytorch.org/whl/cu124
   ```

### Error: "RuntimeError: Data processing error: CAS service error"

Esto es un problema conocido de HuggingFace XET. Ya est√° solucionado en el c√≥digo con `HF_HUB_DISABLE_XET=1`.

### Error de conexi√≥n en WSL2

```bash
# Deshabilitar IPv6
sudo sysctl -w net.ipv6.conf.all.disable_ipv6=1
sudo sysctl -w net.ipv6.conf.default.disable_ipv6=1
```

### Audio generado con mala calidad

- Usa una mejor muestra de referencia (ver gu√≠a arriba)
- Aseg√∫rate de tener GPU habilitada
- Verifica que el texto no tenga caracteres raros

M√°s detalles en: [CHANGELOG.md](CHANGELOG.md) secci√≥n "Fixes Cr√≠ticos"

---

## üìä Rendimiento

Probado en **NVIDIA RTX 3060 12GB** con **CUDA 12.4**:

| Tipo de Texto | Duraci√≥n Audio | Tiempo Generaci√≥n |
|---------------|----------------|-------------------|
| Frase corta (10 palabras) | ~3 segundos | ~6 segundos |
| P√°rrafo (100 palabras) | ~30 segundos | ~30 segundos |
| Guion largo (500 palabras) | ~3 minutos | ~2.5 minutos |

**Ratio promedio:** ~1:1 (genera audio casi en tiempo real con GPU)

---

## üõ£Ô∏è Roadmap

### ‚úÖ Fase 1: MVP (Completado - v0.2.0)
- [x] CLI funcional
- [x] S√≠ntesis de texto b√°sica
- [x] Clonaci√≥n de voz con referencia
- [x] Detecci√≥n autom√°tica de GPU
- [x] Manejo robusto de errores

### ‚úÖ Fase 2.1: UX y Performance (Completado - v0.3.0)
- [x] Barra de progreso visual
- [x] Cache de voces procesadas
- [x] Estimaci√≥n de tiempo de generaci√≥n

### üöß Fase 2.2: Features Avanzadas (Pr√≥ximo)
- [ ] Soporte multiling√ºe (23 idiomas)
- [ ] Modo batch (m√∫ltiples archivos)
- [ ] Detecci√≥n de calidad de audio de referencia

### üìÖ Fase 3: Avanzado (Futuro)
- [ ] Modo interactivo
- [ ] Presets de voces
- [ ] Control de velocidad/tono
- [ ] Detecci√≥n autom√°tica de cap√≠tulos

Ver roadmap completo en: [TODO.md](TODO.md)

---

## ‚öñÔ∏è √âtica y Legalidad

‚ö†Ô∏è **IMPORTANTE:** Este proyecto est√° dise√±ado para uso **√©tico y legal** solamente.

### ‚úÖ Usos Permitidos
- Crear audiolibros con tu propia voz
- Generar voces para proyectos personales/creativos
- Producir contenido donde tienes derechos de la voz
- Experimentaci√≥n y aprendizaje

### ‚ùå Usos Prohibidos
- ‚ùå **Suplantaci√≥n de identidad**
- ‚ùå **Uso de voces sin consentimiento**
- ‚ùå **Enga√±o o fraude**
- ‚ùå **Deepfakes maliciosos**

**Responsabilidad:** El uso de esta herramienta es responsabilidad del usuario. Respeta siempre la privacidad y derechos de las personas.

---

## ü§ù Contribuciones

¬°Las contribuciones son bienvenidas! Si tienes ideas, encuentras bugs, o quieres mejorar el proyecto:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add: Amazing feature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## üìù Licencia

Este proyecto est√° bajo la Licencia MIT. Ver [LICENSE](LICENSE) para m√°s detalles.

---

## üôè Agradecimientos

- **ResembleAI** - Por el modelo Chatterbox TTS de c√≥digo abierto
- **HuggingFace** - Por la infraestructura de modelos
- **uv** (Astral) - Por el gestor de paquetes moderno
- **PyTorch** - Por el framework de deep learning

---

## üìß Contacto

**Mantenedor:** developer
**Repositorio:** [github.com/pyllm-utilities/tts-py](https://github.com/pyllm-utilities/tts-py)
**Issues:** [github.com/pyllm-utilities/tts-py/issues](https://github.com/pyllm-utilities/tts-py/issues)

---

## üîó Enlaces √ötiles

- [Documentaci√≥n de Chatterbox](https://huggingface.co/ResembleAI/chatterbox)
- [uv Documentation](https://github.com/astral-sh/uv)
- [PyTorch CUDA Setup](https://pytorch.org/get-started/locally/)
- [Troubleshooting WSL2 CUDA](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)

---

<div align="center">

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub ‚≠ê**

Made with ‚ù§Ô∏è by the TTS-py team

</div>
